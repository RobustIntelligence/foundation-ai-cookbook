{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a11bde8-d297-492e-91ea-767bcaa47f59",
   "metadata": {},
   "source": [
    "# Use Case Description\n",
    "\n",
    "As a SOC member of your security team, you may often face an overwhelming amount of security-related texts and need a way to quickly identify which ones are critical. <br>\n",
    "Using our models, we can classify cybersecurity-related descriptions -such as excerpts from security blogs or security alert messages- into categories like MITRE ATT&CK IDs or CVSS classes.\n",
    "\n",
    "## Model used for this use case\n",
    "Base Model (Foundation-Sec-8B) is best suited for this use case because the task involves classification, and the output is a single word. <br>\n",
    "**These use cases are more described in detail in [finetuning section](https://github.com/RobustIntelligence/foundation-ai-cookbook/tree/main/3_adoptions/finetuning) to improve performance and stability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d301829-e412-4a0d-be41-e1ed3c80eb6f",
   "metadata": {},
   "source": [
    "## SetUp\n",
    "The setup scripts below are essentially the same as those in the [Quickstart (Foundation-Sec-8B)](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/1_quickstarts/Quickstart_Foundation-Sec-8B.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898bf626-064b-45a2-bb03-cb64a6e9f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "def _get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = _get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689673cc-c952-4a64-8903-480b80940e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dce2005c1c4a87853145d01c8e220b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"fdtn-ai/Foundation-Sec-8B\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path = MODEL_ID,\n",
    "    device_map = \"auto\",\n",
    "    torch_dtype=torch.bfloat16, # Foundation-Sec-8B's tensor_type is BF16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4069bb98-b38d-4310-9ba5-5cd7cd37dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 3, # we only need small new tokens as the outputs are expectedly classes\n",
    "    \"temperature\": None,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4378374-a74f-45a9-86ca-c41697b88e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            **generation_args,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997342d-ab7b-4a6e-9a6e-5479d6a87761",
   "metadata": {},
   "source": [
    "## MITRE ATT&CK ID classification\n",
    "\n",
    "This task involves mapping a given context to the corresponding MITRE ATT&CK ID. <br>\n",
    "To ensure the model responds in the correct format, five example pairs are provided. <br>\n",
    "\"T\" is appended to the prompt to minimize distraction.\n",
    "\n",
    "**The model was fine-tuned using a complete dataset of context-technique pairs in [finetuning_classification_head.ipynb](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/finetuning/finetuning_classification_head.ipynb).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198b0ede-a0f1-4a54-99b5-78fd1cd93274",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "context: This downloader is unique per system and contains a customized backdoor written in Assembler\n",
    "technique: T1059\n",
    "\n",
    "context: This malware was capable of stealing significant system and network information\n",
    "technique: T1082\n",
    "\n",
    "context: Email phishing credential theft\n",
    "technique: T1566\n",
    "\n",
    "context: they are served a ZIP archive containing a malicious LNK file.\n",
    "technique: T1204\n",
    "\n",
    "context: download and deploy Trickbot on the user's machine\n",
    "technique: T1105\n",
    "\n",
    "context: POSHSPY's use of WMI to both store and persist the backdoor code makes it nearly invisible to anyone not familiar with the intricacies of WMI.\n",
    "technique: T'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af201f57-3c9c-42f1-83ef-99686b83c1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T1047'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = inference(prompt)\n",
    "output.split(\"technique: \")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c38064-da2e-4178-bcfd-1a173e526e4a",
   "metadata": {},
   "source": [
    "The model's output is T1047, which is a correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e679d-ef3d-4996-a58a-7fcd4a2fc421",
   "metadata": {},
   "source": [
    "## Common Vulnerability Scoring System (CVSS) vector classification\n",
    "\n",
    "This task involves classifying a given description into the correct label based on the CVSS category. <br>\n",
    "For example, if the category is Attack Vector, choices are Network, Adjacent, Local or Physical, while if the category is Integrity Impact, choices are None, Low or High.\n",
    "\n",
    "**The model was fine-tuned using a complete dataset of context-label pairs in [finetuning_causal_ml.ipynb](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/finetuning/finetuning_causal_ml.ipynb).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf6fdd5-c2f9-4840-81e1-cc0c77bc5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "I have a description about a threat intelligence analysis.\n",
    "\n",
    "description: Cross Site Scripting vulnerability in the input parameter in eyoucms v.1.6.5 allows a remote attacker to run arbitrary code via crafted URL.\n",
    "Regarding Integrity Impact I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: Low\n",
    "\n",
    "description: The EventON WordPress plugin before 2.2 does not sanitise and escape some of its settings, which could allow high privilege users such as admin to perform Stored HTML Injection attacks even when the unfiltered_html capability is disallowed.\n",
    "Regarding Availability Impact I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: None\n",
    "\n",
    "description: A vulnerability, which was classified as critical, was found in Youke365 up to 1.5.3. Affected is an unknown function of the file /app/api/controller/caiji.php of the component Parameter Handler. The manipulation of the argument url leads to server-side request forgery. It is possible to launch the attack remotely. The exploit has been disclosed to the public and may be used. VDB-249870 is the identifier assigned to this vulnerability.\n",
    "Regarding Attack Vector Impact I will answer only one of the following choices in 1 word: Network, Adjacent, Local or Physical\n",
    "My choice: Network\n",
    "\n",
    "description: ASQL injection vulnerability in EmpireCMS v7.5, allows remote attackers to execute arbitrary code and obtain sensitive information via the DoExecSql function.\n",
    "Regarding Confidentiality Impact I will answer only one of the following choices in 1 word: Low or High\n",
    "My choice: High\n",
    "\n",
    "description: IBM WebSphere Application Server Liberty 17.0.0.3 through 24.0.0.4 is vulnerable to a denial of service, caused by sending a specially crafted request. A remote attacker could exploit this vulnerability to cause the server to consume memory resources.  IBM X-Force ID:  280400.\n",
    "Regarding Privileges Required I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: None\n",
    "\n",
    "description: jshERP v3.3 is vulnerable to Arbitrary File Upload. The jshERP-boot/systemConfig/upload interface does not check the uploaded file type, and the biz parameter can be spliced into the upload path, resulting in arbitrary file uploads with controllable paths.\n",
    "Regarding Attack Complexity I will answer only one of the following choices in 1 word: Low or High\n",
    "My choice:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c49f397-05d3-44bc-a978-c7dc4bc184ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Low'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = inference(prompt)\n",
    "output.split(\"My choice:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc14a8c-0500-47a4-a3a4-11031f8e2f5b",
   "metadata": {},
   "source": [
    "The model's output is Low, which is a correct answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
