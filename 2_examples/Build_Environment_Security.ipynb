{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Utils"
      ],
      "metadata": {
        "id": "AI5ozM2h2Nva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "BPloud0h2LI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_model_response(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the content between <think> and the final <|eot_id|> marker.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The full text containing <think> and <|eot_id|> markers.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted content between <think> and <|eot_id|>, or an empty string if not found.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"<think>(.*?)<\\|end_of_text\\|>\", text, re.DOTALL)\n",
        "    return match.group(1).strip() if match else \"\"\n"
      ],
      "metadata": {
        "id": "u5pjZGi32FsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please enter the API key that was provided to you**"
      ],
      "metadata": {
        "id": "QpC9sBBxCdhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"\""
      ],
      "metadata": {
        "id": "v46D7fgiBNZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case - Build Environment Security"
      ],
      "metadata": {
        "id": "7yPwQiB25Cx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Description** - Automate security monitoring and guidance during the software development lifecycle (SDLC) by embedding a GitHub Action that triggers on pull requests (PRs). The system summarizes changes, evaluates them for security risks, and provides actionable recommendations to reviewers. This turns every PR into an opportunity for proactive security posture improvement — not just static scanning, but contextual reasoning."
      ],
      "metadata": {
        "id": "akWRBF0L5PuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Security Analysis Utils"
      ],
      "metadata": {
        "id": "O6zZ0aHC5qC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ci_security_prompt(pr_diff_text):\n",
        "    \"\"\"Create a prompt to analyze security impact of a pull request diff.\"\"\"\n",
        "    return f\"\"\"\n",
        "You are a security expert reviewing changes introduced in a pull request.\n",
        "\n",
        "Analyze the following code diff and identify:\n",
        "1. Security-relevant changes\n",
        "2. Any potential vulnerabilities introduced\n",
        "3. A clear summary of affected areas\n",
        "4. Recommended remediations (if needed)\n",
        "\n",
        "## PULL REQUEST DIFF\n",
        "{pr_diff_text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7MygePTN5IPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ci_security_analysis(pr_diff):\n",
        "    \"\"\"Send the diff to an AI model for security analysis and return the response.\"\"\"\n",
        "    prompt = create_ci_security_prompt(pr_diff)\n",
        "\n",
        "    resp = requests.post(\n",
        "        \"https://model-8w6j1ojq.api.baseten.co/development/predict\",\n",
        "        headers={\"Authorization\": f\"Api-Key {API_KEY}\"},\n",
        "        json={\"prompt\": prompt},\n",
        "    )\n",
        "\n",
        "    return extract_model_response(resp.text)"
      ],
      "metadata": {
        "id": "9jtsZWs05eGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage"
      ],
      "metadata": {
        "id": "IYNIGWRS52AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this sample PR Diff, Replaced use of `eval()` with `ast.literal_eval()` — this is a significant security improvement. `eval()` can execute arbitrary code, whereas `ast.literal_eval()` safely evaluates strings with Python literals.\n"
      ],
      "metadata": {
        "id": "9K1B2Tlj65Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pr_diff = \"\"\"\n",
        "diff --git a/app/utils.py b/app/utils.py\n",
        "index e69de29..b25a3c0 100644\n",
        "--- a/app/utils.py\n",
        "+++ b/app/utils.py\n",
        "@@ def process_input(data):\n",
        "-    return eval(data)\n",
        "+    import ast\n",
        "+    return ast.literal_eval(data)\n",
        "\n",
        "diff --git a/.github/workflows/deploy.yml b/.github/workflows/deploy.yml\n",
        "index a1b2c3d..d4e5f6g 100644\n",
        "--- a/.github/workflows/deploy.yml\n",
        "+++ b/.github/workflows/deploy.yml\n",
        "@@ steps:\n",
        "-      run: npm run deploy\n",
        "+      run: |\n",
        "+        set -e\n",
        "+        npm run lint\n",
        "+        npm test\n",
        "+        npm run deploy\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "1JYLY8sB50RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = run_ci_security_analysis(sample_pr_diff)"
      ],
      "metadata": {
        "id": "anIgch7F6a8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN4h97hq6kbt",
        "outputId": "b5160c3c-c75b-4a2a-a67f-187e4472d701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Security-Relevant Changes:**\n",
            "\n",
            "1. The `process_input` function has been modified to use `ast.literal_eval` instead of `eval`.\n",
            "2. The GitHub Actions workflow file (`deploy.yml`) now includes additional commands before running `npm run deploy`.\n",
            "\n",
            "**Potential Vulnerabilities Introduced:**\n",
            "\n",
            "None identified in this diff. However, there might be some minor issues:\n",
            "\n",
            "* In the `process_input` function, using `ast.literal_eval` is generally safer than `eval`, as it only evaluates literals (strings, numbers, etc.) and not arbitrary code. But if the input data contains complex structures like lists or dictionaries with untrusted values, it may still lead to errors. To mitigate this, consider validating user input before processing.\n",
            "* The GitHub Actions workflow now runs `npm test` before deploying. While this is a good practice for ensuring tests pass before deployment, it's essential to ensure that the tests cover all critical aspects of the application, including security-related checks.\n",
            "\n",
            "**Affected Areas:**\n",
            "\n",
            "1. `app/utils.py`: The `process_input` function, which handles user input processing.\n",
            "2. `.github/workflows/deploy.yml`: The GitHub Actions workflow for deployment.\n",
            "\n",
            "**Recommended Remediations:**\n",
            "\n",
            "1. **Input Validation:** Add input validation mechanisms to ensure that user-provided data conforms to expected formats. This can prevent unexpected errors when using `ast.literal_eval`. Consider using libraries like `voluptuous` or `pydantic` for schema-based validation.\n",
            "2. **Test Coverage:** Review the existing tests to ensure they adequately cover security-critical paths. If necessary, add new tests to verify that sensitive operations are properly secured.\n",
            "3. **Code Review:** Perform a thorough code review on the updated `process_input` function to confirm that it correctly handles edge cases and potential attacks.\n",
            "4. **Dependency Updates:** Ensure that all dependencies used by the project are up-to-date, especially those related to parsing or evaluating user input. Regularly update dependencies to patch known vulnerabilities.\n",
            "\n",
            "Example of improved input validation using `voluptuous`:\n",
            "```python\n",
            "import voluptuous as v\n",
            "\n",
            "def process_input(data):\n",
            "    schema = v.Schema({'key': str})\n",
            "    try:\n",
            "        validated_data = schema(data)\n",
            "        return ast.literal_eval(validated_data['key'])\n",
            "    except v.Invalid as err:\n",
            "        # Handle invalid input\n",
            "        raise ValueError(err)\n",
            "```\n",
            "Note: This example assumes a simple string key; adjust the schema according to your actual data structure.\n"
          ]
        }
      ]
    }
  ]
}