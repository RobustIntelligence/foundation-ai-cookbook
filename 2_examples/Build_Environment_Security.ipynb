{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI5ozM2h2Nva"
   },
   "source": [
    "# Use Case Description\n",
    "\n",
    "Automate security monitoring and guidance during the software development lifecycle (SDLC) by embedding a GitHub Action that triggers on pull requests (PRs). The system summarizes changes, evaluates them for security risks, and provides actionable recommendations to reviewers. This turns every PR into an opportunity for proactive security posture improvement — not just static scanning, but contextual reasoning.\n",
    "\n",
    "## Model used for this use case\n",
    "Both Instruct Model and Reasoning Model would be suitable for this task. In this example, we used Instruct Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPloud0h2LI9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SetUp\n",
    "\n",
    "The setup scripts below are essentially the same as those in the [Quickstart (Instruct Model)](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/1_quickstarts/Preview_Quickstart_instruct_model.ipynb)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u5pjZGi32FsI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v46D7fgiBNZF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0412015fcbe34773b9bf0d000d17fc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"\" # To be relaced with the final model name\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, # this model's tensor_type is BF16\n",
    "    token=HF_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": None,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def inference(prompt, system_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(inputs, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            **generation_args,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens = False)\n",
    "    \n",
    "    # extract the assistant response part only\n",
    "    match = re.search(r\"<\\|assistant\\|>(.*?)<\\|end_of_text\\|>\", response, re.DOTALL)\n",
    "    \n",
    "    return match.group(1).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6zZ0aHC5qC_"
   },
   "source": [
    "## Security Analysis Utils\n",
    "\n",
    "In this sample PR Diff, Replaced use of `eval()` with `ast.literal_eval()` — this is a significant security improvement. `eval()` can execute arbitrary code, whereas `ast.literal_eval()` safely evaluates strings with Python literals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_diff_text = \"\"\"\n",
    "diff --git a/app/utils.py b/app/utils.py\n",
    "index e69de29..b25a3c0 100644\n",
    "--- a/app/utils.py\n",
    "+++ b/app/utils.py\n",
    "@@ def process_input(data):\n",
    "-    return eval(data)\n",
    "+    import ast\n",
    "+    return ast.literal_eval(data)\n",
    "\n",
    "diff --git a/.github/workflows/deploy.yml b/.github/workflows/deploy.yml\n",
    "index a1b2c3d..d4e5f6g 100644\n",
    "--- a/.github/workflows/deploy.yml\n",
    "+++ b/.github/workflows/deploy.yml\n",
    "@@ steps:\n",
    "-      run: npm run deploy\n",
    "+      run: |\n",
    "+        set -e\n",
    "+        npm run lint\n",
    "+        npm test\n",
    "+        npm run deploy\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a security expert reviewing changes introduced in a pull request.\"\n",
    "\n",
    "prompt = f'''Analyze the following code diff and identify:\n",
    "1. Security-relevant changes\n",
    "2. Any potential vulnerabilities introduced\n",
    "3. A clear summary of affected areas\n",
    "4. Recommended remediations (if needed)\n",
    "\n",
    "## PULL REQUEST DIFF\n",
    "{pr_diff_text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Analysis:\n",
       "\n",
       "#### 1. **Security-Relevant Changes**\n",
       "\n",
       "**In `app/utils.py`:**\n",
       "The change from using Python's built-in `eval` function to use `ast.literal_eval` for processing input data is significant.\n",
       "\n",
       "*Before:* \n",
       "```python\n",
       "def process_input(data):\n",
       "    return eval(data) # This can evaluate arbitrary expressions, which poses serious security risks if 'data' contains untrusted content.\n",
       "```\n",
       "\n",
       "*After:*\n",
       "```python\n",
       "import ast\n",
       "def process_input(data):\n",
       "    return ast.literal_eval(data) # Safer than eval as it only evaluates strings that could be assigned to an identifier or expression\n",
       "```\n",
       "Using `eval()` on user-provided data has been replaced with `ast.literal_eval()`, which is generally safer because it does not allow execution of arbitrary commands but rather converts a string into a python literal object like int, float, str etc., without evaluating any expressions.\n",
       "\n",
       "However, this doesn't completely eliminate all risk since `literal_eval` still allows evaluation of certain constructs such as numbers, strings, lists, tuples, sets, dictionaries, booleans, None, and identifiers that resolve to constants.\n",
       "\n",
       "**In `.github/workflows/deploy.yml`:**\n",
       "There have been no direct security-related changes here; however, there might be indirect implications due to improved testing (`npm test`) being added before deployment.\n",
       "\n",
       "*Before:*\n",
       "```yaml\n",
       "steps:\n",
       "  - name: Build and Deploy\n",
       "    run: npm run deploy\n",
       "```\n",
       "\n",
       "*After:*\n",
       "```yaml\n",
       "steps:\n",
       "  - name: Lint & Test Before Deployment\n",
       "    run: |\n",
       "      set -e\n",
       "      npm run lint\n",
       "      npm test\n",
       "      npm run deploy\n",
       "```\n",
       "Adding linter checks and tests before deploying ensures better quality control and potentially catches issues earlier, indirectly contributing to overall system stability and reducing the likelihood of introducing new bugs or regressions that may lead to security problems.\n",
       "\n",
       "#### 2. **Potential Vulnerabilities Introduced**\n",
       "\n",
       "While the switch from `eval` to `ast.literal_eval` mitigates some risks associated with executing arbitrary code, it’s important to note that `ast.literal_eval` isn’t entirely safe against all types of attacks. For instance, it will convert a string representing a list comprehension or dictionary comprehension into a real Python object, which could execute malicious logic under specific circumstances.\n",
       "\n",
       "Moreover, while the workflow file itself hasn't changed directly related to security concerns, relying solely on manual review processes within CI/CD pipelines can sometimes miss critical errors or misconfigurations leading to other kinds of pipeline failures or even leaks.\n",
       "\n",
       "#### 3. **Summary of Affected Areas**\n",
       "\n",
       "- The primary focus of these changes is on improving safety when handling user-supplied data by replacing `eval` with `ast.literal_eval`.\n",
       "- There was also an enhancement made to the build and release process by adding static analysis via `npm run lint` and unit tests through `npm test` prior to running the actual deployment command.\n",
       "\n",
       "#### 4. **Recommended Remediations (If Needed)**\n",
       "\n",
       "Given the context provided:\n",
       "\n",
       "- It would be advisable to conduct thorough testing around how complex inputs are handled after switching to `ast.literal_eval`. Ensure that edge cases involving nested structures (like deeply-nested lists/dicts containing various types including possibly unsafe ones) do not pose unexpected risks.\n",
       "  \n",
       "- While `ast.literal_eval` improves upon `eval`, consider further hardening by validating and sanitizing input where possible instead of relying purely on parsing. \n",
       "\n",
       "- Continuously monitor the effectiveness of the newly included pre-deployment checks (`lint` and `test`). If they uncover frequent issues, reconsider whether more robust automated checks should be integrated into the pipeline.\n",
       "\n",
       "- Regularly audit third-party dependencies used during both development and production stages to ensure no known vulnerabilities exist in them.\n",
       "\n",
       "By making these considerations, you'll help maintain the integrity and security posture of your application over time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = inference(prompt, SYSTEM_PROMPT)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
