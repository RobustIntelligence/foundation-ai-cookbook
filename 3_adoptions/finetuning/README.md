# Finetuning

This section covers fine-tuning the base model using [a cybersecurity classification use case](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/2_examples/Classification_cybersecurity_descriptions.ipynb) from the examples. 
We demonstrate two methods:
1. Retaining the original causal language model structure ([link](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/finetuning/finetuning_causal_ml.ipynb))
2. Replacing the last layer with a classification head ([link](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/finetuning/finetuning_classification_head.ipynb))
