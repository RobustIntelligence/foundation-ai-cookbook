{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d1dfc7-5af1-4e2d-b530-eb46a0ede849",
   "metadata": {},
   "source": [
    "# Finetuning as CausalML\n",
    "\n",
    "**This use case is an extention of [Classification_cybersecurity_descriptions](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/2_examples/Classification_cybersecurity_descriptions.ipynb) shown in 2_examples**\n",
    "\n",
    "For this demo, we use datasets of CTI-VSP (Cyber Threat Intelligence Vulnerability Severity Prediction) to predict items of the Common Vulnerability Scoring System (CVSS) vector. **The dataset is NOT used for training of Foundation-Sec-8B model.**\n",
    "\n",
    "For example, given an description of \n",
    "```In the Linux kernel through 6.7.1, there is a use-after-free in cec_queue_msg_fh, related to drivers/media/cec/core/cec-adap.c and drivers/media/cec/core/cec-api.c.```, the model is asked to classify the description to correct labels based on the category in question. <br>\n",
    "If the category is Attack Vector, choices are Network, Adjacent, Local or Physical, while if the category is Integrity Impact, choices are None, Low or High.\n",
    "\n",
    "\n",
    "To see the details of datasets, refer to\n",
    "- Paper: https://arxiv.org/pdf/2406.07599 <br>\n",
    "- GitHub: https://github.com/xashru/cti-bench/tree/main\n",
    "\n",
    "Note that we have modified the datasets to suit our use case. <br>\n",
    "We'll finetune Foundation-Sec-8B as well as original llama model to show how finetuning works, and how Foundation-Sec-8B outperforms the original model.\n",
    "\n",
    "### Hardware\n",
    "This finetuning has been conducted under Nvidia 8xA100 (80GB) GPUs. Though it's doable with 1 GPU, it'll be slower. If you don't have enough memories, consider enabling QLoRa. That'll save memories at the cost of small performance degration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2db7d-3805-430c-89d0-472b6aaecff9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d1e52c-24bb-4c73-8290-3d4c0056d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13ccb21-70cb-4646-85d3-d38ec4e5f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106473bc-619f-426b-9dbc-a30591b5c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ce211-7921-4631-85f3-07043d491db6",
   "metadata": {},
   "source": [
    "# Model Download & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7c4b12-e721-4614-bcbd-e1c9ac2afb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "WB_PROJECT_NAME = \"finetuning_demo\"\n",
    "\n",
    "LLAMA_MODEL_ID = \"meta-llama/Llama-3.1-8B\"\n",
    "FOUNDATION_SEC_8B_MODEL_ID = \"fdtn-ai/Foundation-Sec-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a254547-8fbd-4262-b6d0-44c644950588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# tokenizer is the same for all processes\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL_ID)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7f06c9-8371-44f7-9a70-91969c3baa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id):\n",
    "\n",
    "    # Comment out below if you want to disable QLoRa for normal LoRa\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type = \"nf4\",\n",
    "        bnb_4bit_compute_dtype = \"float16\",\n",
    "        bnb_4bit_use_double_quant = True\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path = model_id,\n",
    "        device_map = DEVICE,\n",
    "        quantization_config = bnb_config,\n",
    "    ).to(DEVICE)\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    model.generation_config.top_p = None\n",
    "    model.generation_config.temperature = None\n",
    "    model.generation_config.pad_token_id = tokenizer.eos_token_id    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3946ba-17e7-4169-b299-fe48edb1de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = \"My choice:\"\n",
    "MAX_LENGTH = 1024\n",
    "MAX_NEW_TOKEN = 3\n",
    "\n",
    "def inference(prompt, model):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        _output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens = MAX_NEW_TOKEN,\n",
    "            do_sample = False,\n",
    "            repetition_penalty = 1.2,\n",
    "        )\n",
    "    output = tokenizer.decode(_output[0], skip_special_tokens = True)\n",
    "    response = output.split(splitter)[-1].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954585e4-5ca5-4c79-b446-99a776b2cc41",
   "metadata": {},
   "source": [
    "Let's see how each model works with an example. \n",
    "\n",
    "Give a prompt to each model and see what the output looks like. <br>\n",
    "The correct answer is **High**. Original llama failed to answer correctly, while Foundation-Sec-8B did successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea3e043-5582-43b6-8232-765bc70f6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "I have a description about a threat intelligence analysis.\n",
    "\n",
    "description: Cross Site Scripting vulnerability in the input parameter in eyoucms v.1.6.5 allows a remote attacker to run arbitrary code via crafted URL.\n",
    "Regarding Integrity Impact I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: Low\n",
    "\n",
    "description: The EventON WordPress plugin before 2.2 does not sanitise and escape some of its settings, which could allow high privilege users such as admin to perform Stored HTML Injection attacks even when the unfiltered_html capability is disallowed.\n",
    "Regarding Availability Impact I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: None\n",
    "\n",
    "description: A vulnerability, which was classified as critical, was found in Youke365 up to 1.5.3. Affected is an unknown function of the file /app/api/controller/caiji.php of the component Parameter Handler. The manipulation of the argument url leads to server-side request forgery. It is possible to launch the attack remotely. The exploit has been disclosed to the public and may be used. VDB-249870 is the identifier assigned to this vulnerability.\n",
    "Regarding Attack Vector Impact I will answer only one of the following choices in 1 word: Network, Adjacent, Local or Physical\n",
    "My choice: Network\n",
    "\n",
    "description: ASQL injection vulnerability in EmpireCMS v7.5, allows remote attackers to execute arbitrary code and obtain sensitive information via the DoExecSql function.\n",
    "Regarding Confidentiality Impact I will answer only one of the following choices in 1 word: Low or High\n",
    "My choice: High\n",
    "\n",
    "description: IBM WebSphere Application Server Liberty 17.0.0.3 through 24.0.0.4 is vulnerable to a denial of service, caused by sending a specially crafted request. A remote attacker could exploit this vulnerability to cause the server to consume memory resources.  IBM X-Force ID:  280400.\n",
    "Regarding Privileges Required I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice: None\n",
    "\n",
    "description: In vsp driver, there is a possible use after free due to a logic error. This could lead to local denial of service with System execution privileges needed\n",
    "Regarding Privileges Required I will answer only one of the following choices in 1 word: None, Low or High\n",
    "My choice:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b1007-7678-420c-8040-8971d479b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6ee227e52f428b834c00ff530929ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-3.1-8B's answer: None\n"
     ]
    }
   ],
   "source": [
    "llama_model = load_model(LLAMA_MODEL_ID)\n",
    "llama_output_test = inference(prompt, llama_model)\n",
    "\n",
    "#To avoid OOM error load model one by one and remove models not currently being used\n",
    "import gc\n",
    "\n",
    "llama_model = None\n",
    "gc.collect()\n",
    "\n",
    "print(\"Llama-3.1-8B's answer:\", llama_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c002ee0f-a8ae-445c-bb0f-23c45f1a31cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c3ac9386804a67b7927a6a02711372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundation-Sec-8B's answer: High\n"
     ]
    }
   ],
   "source": [
    "foundation_sec_8b_model = load_model(FOUNDATION_SEC_8B_MODEL_ID)\n",
    "foundation_sec_8b_output_test = inference(prompt, foundation_sec_8b_model)\n",
    "\n",
    "foundation_sec_8b_model = None\n",
    "gc.collect()\n",
    "\n",
    "print(\"Foundation-Sec-8B's answer:\", foundation_sec_8b_output_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37a1e4-36b5-4a1c-a800-c069afb43974",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Let's download datasets and pre-process them for evaluation and finetuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28669297-e0f3-4054-a741-e6716b380cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''I have a description about a threat intelligence analysis.\n",
    "description: {description}\n",
    "Regarding {category} I will answer only one of the following choices in 1 word: {choices}\n",
    "My choice:'''\n",
    "\n",
    "finetuning_prompt_template = '''I have a description about a threat intelligence analysis.\n",
    "description: {description}\n",
    "Regarding {category} I will answer only one of the following choices in 1 word: {choices}\n",
    "My choice:{label}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7859ec50-0c08-403f-9627-e885f6eef41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from https://github.com/xashru/cti-bench/blob/main/data/cti-vsp.tsv first\n",
    "# Here it's assumed that cti-vsp is downloaded at cti-vsp directory\n",
    "from pathlib import Path\n",
    "\n",
    "PATH_TO_CTI_VSP = Path(\"cti-vsp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db994e-09eb-4c6b-bdf4-625dc232f94e",
   "metadata": {},
   "source": [
    "Since each record has 8 categories to be classified, split each record to 8 pairs of description and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20fe2545-2ede-4a04-99f2-a79ec6d1912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset summary \n",
      "\n",
      "                                   description\n",
      "category               label                 \n",
      "Attack Complexity      High                28\n",
      "                       Low                960\n",
      "Attack Vector          Adjacent            16\n",
      "                       Local              187\n",
      "                       Network            783\n",
      "                       Physical             2\n",
      "Availability Impact    High               560\n",
      "                       Low                  9\n",
      "                       None               419\n",
      "Confidentiality Impact High               544\n",
      "                       Low                278\n",
      "                       None               166\n",
      "Integrity Impact       High               482\n",
      "                       Low                279\n",
      "                       None               227\n",
      "Privileges Required    High                83\n",
      "                       Low                337\n",
      "                       None               568\n",
      "Scope                  Changed            252\n",
      "                       Unchanged          736\n",
      "User Interaction       None               632\n",
      "                       Required           356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "VULNERABILITY_CATEGORIES_SHORT = [\n",
    "    \"AV\",\n",
    "    \"AC\",\n",
    "    \"PR\",\n",
    "    \"UI\",\n",
    "    \"S\",\n",
    "    \"C\",\n",
    "    \"I\",\n",
    "    \"A\"\n",
    "]\n",
    "VULNERABILITY_CATEGORIES_LONG = [\n",
    "    \"Attack Vector\",\n",
    "    \"Attack Complexity\",\n",
    "    \"Privileges Required\",\n",
    "    \"User Interaction\",\n",
    "    \"Scope\",\n",
    "    \"Confidentiality Impact\",\n",
    "    \"Integrity Impact\",\n",
    "    \"Availability Impact\"\n",
    "]\n",
    "NOT_FOUND = \"N/A\"\n",
    "\n",
    "\n",
    "def _extract_label(combined_labels_str):\n",
    "\n",
    "    combined_labels_str = combined_labels_str.replace(\"CVSS:3.1\", \"\")\n",
    "\n",
    "    def _extract_label_from_vector(combined_labels_str, category):\n",
    "        match = re.search(rf'/{category}:([^/]+)', combined_labels_str)\n",
    "        if match:\n",
    "            return _map_to_full_labels(category, match.group(1))\n",
    "        return NOT_FOUND\n",
    "\n",
    "    return [_extract_label_from_vector(combined_labels_str, category) for category in VULNERABILITY_CATEGORIES_SHORT]\n",
    "\n",
    "\n",
    "# - Attack Vector (AV): Network (N), Adjacent (A), Local (L), Physical (P)\n",
    "# - Attack Complexity (AC): Low (L), High (H)\n",
    "# - Privileges Required (PR): None (N), Low (L), High (H)\n",
    "# - User Interaction (UI): None (N), Required (R)\n",
    "# - Scope (S): Unchanged (U), Changed (C)\n",
    "# - Confidentiality (C): None (N), Low (L), High (H)\n",
    "# - Integrity (I): None (N), Low (L), High (H)\n",
    "# - Availability (A): None (N), Low (L), High (H)\n",
    "def _map_to_full_labels(category, label):\n",
    "    mapping = {\n",
    "        \"AV\": {\n",
    "            \"N\": \"Network\",\n",
    "            \"A\": \"Adjacent\",\n",
    "            \"L\": \"Local\",\n",
    "            \"P\": \"Physical\",\n",
    "        },\n",
    "        \"AC\": {\n",
    "            \"L\": \"Low\",\n",
    "            \"H\": \"High\",\n",
    "        },\n",
    "        \"PR\": {\n",
    "            \"N\": \"None\",\n",
    "            \"L\": \"Low\",\n",
    "            \"H\": \"High\",\n",
    "        },\n",
    "        \"UI\": {\n",
    "            \"N\": \"None\",\n",
    "            \"R\": \"Required\",\n",
    "        },\n",
    "        \"S\": {\n",
    "            \"U\": \"Unchanged\",\n",
    "            \"C\": \"Changed\",\n",
    "        },\n",
    "        \"C\": {\n",
    "            \"N\": \"None\",\n",
    "            \"L\": \"Low\",\n",
    "            \"H\": \"High\",\n",
    "        },\n",
    "        \"I\": {\n",
    "            \"N\": \"None\",\n",
    "            \"L\": \"Low\",\n",
    "            \"H\": \"High\",\n",
    "        },\n",
    "        \"A\": {\n",
    "            \"N\": \"None\",\n",
    "            \"L\": \"Low\",\n",
    "            \"H\": \"High\",\n",
    "        },\n",
    "    }\n",
    "    return mapping[category][label]\n",
    "\n",
    "\n",
    "def extract_labels(tsv_path, output_csv_path):\n",
    "    _df = pd.read_csv(tsv_path, sep='\\t')\n",
    "    rows = []\n",
    "    descriptions = _df[\"Description\"].to_list()\n",
    "    combined_labels = _df[\"GT\"].to_list() \n",
    "    for desc, cb in zip(descriptions, combined_labels):\n",
    "        labels = _extract_label(cb)\n",
    "        assert len(labels) == len(VULNERABILITY_CATEGORIES_LONG)\n",
    "        for i in range(len(VULNERABILITY_CATEGORIES_LONG)):\n",
    "            rows.append([VULNERABILITY_CATEGORIES_LONG[i], desc, labels[i]])\n",
    "    df = pd.DataFrame(rows, columns=[\"category\", \"description\", \"label\"])\n",
    "    df = df.drop_duplicates().set_index(\"category\")\n",
    "    print(\"Dataset summary \\n\\n\", df.groupby([\"category\", \"label\"]).count())    \n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_benchmark_by_majority_classifier(dataset):\n",
    "    eval_datasets = dataset\n",
    "    total_len = len(eval_datasets)\n",
    "    df_eval_datasets = eval_datasets.to_pandas()\n",
    "    df_group = df_eval_datasets.groupby([\"category\", \"label\"]).count()\n",
    "    df_group = df_group.reset_index()\n",
    "    df_group = df_group.set_index(\"category\")\n",
    "    df_group[\"category_total\"] = df_group.groupby(df_group.index).sum()[\"description\"]\n",
    "    df_group[\"pct\"] = df_group[\"description\"] / df_group[\"category_total\"]\n",
    "    df_group[\"weighted_pct\"] = df_group[\"pct\"] * df_group[\"category_total\"] / total_len\n",
    "    accuracy = df_group.groupby(df_group.index).max().sum()[\"weighted_pct\"]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "TSV_PATH = PATH_TO_CTI_VSP / \"cti-vsp.tsv\"\n",
    "CSV_PATH = PATH_TO_CTI_VSP / \"modified_cti-vsp.csv\"\n",
    "df = extract_labels(TSV_PATH, CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b877674-63e9-4f0c-91af-37daff565f6e",
   "metadata": {},
   "source": [
    "Split the datasets into train and eval and save to disk. <br>\n",
    "Let's also calculate benchmark of major class classifier for comparison with metrics by finetuned models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d3cd22-5982-445c-b193-1ee418c8c442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116260e1aada484a8d84b1c3fb325c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6323 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f61edb0df34450e8028f177981e8d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark by majority classifier: 0.6629\n"
     ]
    }
   ],
   "source": [
    "HF_DATASET_NAME = \"hf_dataset\"\n",
    "\n",
    "SPLIT_SIZE = 0.2\n",
    "SEED = 42\n",
    "dataset = Dataset.from_pandas(df).train_test_split(test_size = SPLIT_SIZE, shuffle = True, seed = SEED)\n",
    "dataset.save_to_disk(PATH_TO_CTI_VSP / HF_DATASET_NAME)\n",
    "benchmark = get_benchmark_by_majority_classifier(dataset[\"test\"])\n",
    "print(\"\\nBenchmark by majority classifier:\", round(benchmark, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4900d5b-addb-4c97-826d-0a2f5ef4791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VSP_MAPPING = {\n",
    "    \"Attack Vector\": \"Network, Adjacent, Local or Physical\",\n",
    "    \"Attack Complexity\": \"Low or High\",\n",
    "    \"Privileges Required\": \"None, Low or High\",\n",
    "    \"User Interaction\": \"None or Required\",\n",
    "    \"Scope\": \"Unchanged or Changed\",\n",
    "    \"Confidentiality Impact\": \"None, Low or High\",\n",
    "    \"Integrity Impact\": \"None, Low or High\",\n",
    "    \"Availability Impact\": \"None, Low or High\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_dataset_and_preprocess():\n",
    "\n",
    "    remove_columns = [\"category\", \"description\", \"label\"]\n",
    "\n",
    "    def _preprocess_data(examples):\n",
    "\n",
    "        prompts = [\n",
    "            finetuning_prompt_template.format(\n",
    "                description = description[:MAX_LENGTH - 100], #truncate description to avoid exceeding max_length,\n",
    "                category = category,\n",
    "                label = label,\n",
    "                choices = VSP_MAPPING[category],\n",
    "            )\n",
    "            for description, category, label in zip(\n",
    "                examples[\"description\"],\n",
    "                examples[\"category\"],\n",
    "                examples[\"label\"],\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return tokenizer(prompts, truncation = True, padding = \"max_length\", max_length = MAX_LENGTH)\n",
    "\n",
    "    hf_datasets = load_from_disk(PATH_TO_CTI_VSP /  HF_DATASET_NAME)\n",
    "    train_data = hf_datasets[\"train\"]\n",
    "    test_data = hf_datasets[\"test\"]\n",
    "    tokenized_train = train_data.map(_preprocess_data, batched = True, remove_columns = remove_columns)\n",
    "    tokenized_test = test_data.map(_preprocess_data, batched = True, remove_columns = remove_columns)\n",
    "    print(f\"Train samples: {len(tokenized_train)}, Test samples: {len(tokenized_test)}\")\n",
    "\n",
    "    return tokenized_train, tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02edcf50-fc56-4c4e-9548-47118aee70cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6323, Test samples: 1581\n"
     ]
    }
   ],
   "source": [
    "tokenized_train, tokenized_test = load_dataset_and_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e525584-0ccd-48b9-b290-2c9ed939112c",
   "metadata": {},
   "source": [
    "# Evaluation (before finetuning)\n",
    "\n",
    "Let's see how models perform before finetuing is conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "142e2663-5dff-46b3-b604-3a315bba5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts_and_labels():\n",
    "    hf_dataset = load_from_disk(PATH_TO_CTI_VSP / HF_DATASET_NAME)\n",
    "    df = hf_dataset[\"test\"].to_pandas()\n",
    "    prompts = []\n",
    "    labels = []\n",
    "    for row in df.iterrows():\n",
    "        row = row[1]\n",
    "        category = row['category']\n",
    "        choices = VSP_MAPPING[category]\n",
    "        description = row['description']\n",
    "        label = row['label']\n",
    "        prompt = prompt_template.format(description=description, category=category, choices=choices)\n",
    "        prompts.append(prompt)\n",
    "        labels.append(label)\n",
    "    return prompts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7dc519-9e5e-49ab-aeda-e0c174a9d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pred(prompts, labels, model):\n",
    "    preds = [inference(prompt, model) for prompt in prompts]\n",
    "    num_exist = sum(1 for label, pred in zip(labels, preds) if str(label).lower() in str(pred).lower())\n",
    "    print(f\"{num_exist} out of total {len(labels)}\")\n",
    "    return round(num_exist/len(labels), 4)\n",
    "\n",
    "def eval(model_id):\n",
    "    model = load_model(model_id)\n",
    "    prompts, labels = get_prompts_and_labels()\n",
    "    result = evaluate_pred(prompts, labels, model)\n",
    "    print(f\"Accuracy: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f408f39-9652-482e-bfc5-40136bc49eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed5e27bdf9e4c66a3d034d256feef4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674 out of total 1581\n",
      "Accuracy: 0.4263\n"
     ]
    }
   ],
   "source": [
    "eval(LLAMA_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e19f92a0-4d57-46c3-9d43-eb8e2465ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eb82b0cbf3490ea85f49960cad30b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890 out of total 1581\n",
      "Accuracy: 0.5629\n"
     ]
    }
   ],
   "source": [
    "eval(FOUNDATION_SEC_8B_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e557b-9a60-4289-94c2-ed10eafeb8e5",
   "metadata": {},
   "source": [
    "It shows that Foundation-Sec-8B already outperforms the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca1fc9-904d-43f1-84c1-07df4c3a9348",
   "metadata": {},
   "source": [
    "# Finetuning & Evaluation\n",
    "\n",
    "Let's finetune the models using QLoRa approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6ab8900-1a96-4d8f-8ab1-53f38a9ea772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "OUTPUT_DIR = \"./checkpoints\"\n",
    "\n",
    "def train(model_id):\n",
    "\n",
    "    _output_dir = Path(OUTPUT_DIR) / str(f\"{model_id}\").replace(\"/\", \"_\")\n",
    "\n",
    "    model = load_model(model_id)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = _output_dir,\n",
    "        label_names = [\"labels\"],\n",
    "        run_name = \"finetuning_demo\",\n",
    "        num_train_epochs = 10,\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        eval_strategy = \"no\",\n",
    "        logging_steps = 50,\n",
    "        learning_rate = 4.e-5,\n",
    "        weight_decay = 0.001,\n",
    "        fp16 = False,\n",
    "        bf16 = False,\n",
    "        max_grad_norm = 0.3,\n",
    "        max_steps = -1,\n",
    "        group_by_length = True,\n",
    "        lr_scheduler_type = \"constant\",\n",
    "        seed = SEED,\n",
    "        report_to = [\"none\"],\n",
    "    )\n",
    "    \n",
    "    peft_parameters = LoraConfig(\n",
    "        lora_alpha = 8,\n",
    "        lora_dropout = 0.1,\n",
    "        r = 8,\n",
    "        bias = \"none\",\n",
    "        task_type = \"CAUSAL_LM\",\n",
    "    )\n",
    "    peft_model = get_peft_model(model, peft_parameters)\n",
    "    peft_model.print_trainable_parameters()\n",
    "\n",
    "    data_collator = DataCollatorForCompletionOnlyLM(response_template = \"My choice\", tokenizer = tokenizer)\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model = peft_model,\n",
    "        train_dataset = tokenized_train,\n",
    "        eval_dataset = tokenized_test,\n",
    "        peft_config = peft_parameters,\n",
    "        args = training_args,\n",
    "        data_collator = data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08029934-0b96-49e1-a2c9-33f75acea04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_finetuned_model(original_model_id):\n",
    "    _dir = Path(OUTPUT_DIR) / str(f\"{original_model_id}\").replace(\"/\", \"_\")\n",
    "    last_checkpoint = get_last_checkpoint(_dir)\n",
    "    print(\"last_checkpoint:\", last_checkpoint)\n",
    "    peft_config = PeftConfig.from_pretrained(last_checkpoint)\n",
    "    orginal_model = AutoModelForCausalLM.from_pretrained(\n",
    "        original_model_id,\n",
    "        torch_dtype = torch.float16,\n",
    "        device_map = DEVICE,\n",
    "    )\n",
    "    peft_model = PeftModel.from_pretrained(orginal_model, last_checkpoint, is_trainable=True)\n",
    "    model = peft_model.merge_and_unload()\n",
    "    model.generation_config.top_p = None\n",
    "    model.generation_config.temperature = None\n",
    "    model.generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_finetuning(original_model_id):\n",
    "    model = load_finetuned_model(original_model_id)\n",
    "    prompts, labels = get_prompts_and_labels()\n",
    "    result = evaluate_pred(prompts, labels, model)\n",
    "    print(f\"metrics: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c232694b-d5a3-4819-855e-7eb7941216d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd03221a1d3743e6a8fe3b885faf8e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [980/980 46:43, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.018600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(LLAMA_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0f73f5a-bebb-4bec-9c36-5d26916baf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_checkpoint: checkpoints/meta-llama_Llama-3.1-8B/checkpoint-980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a75139d282442a9f83b539e684f442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383 out of total 1581\n",
      "metrics: 0.8748\n"
     ]
    }
   ],
   "source": [
    "eval_finetuning(LLAMA_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306545e0-f288-458c-b339-5e678e0afa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774d68097bd54999ae0a65f8e68b0523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,034,717,696 || trainable%: 0.0424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [980/980 46:53, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(FOUNDATION_SEC_8B_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66e24bfe-4ff9-4e6a-8797-7a7e3a6b965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_checkpoint: checkpoints/fdtn-ai_Foundation-Sec-8B/checkpoint-980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79882730af444beabd0268c6c42577f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446 out of total 1581\n",
      "metrics: 0.9146\n"
     ]
    }
   ],
   "source": [
    "eval_finetuning(FOUNDATION_SEC_8B_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f842-c024-4e88-9c04-61f26c3b3d10",
   "metadata": {},
   "source": [
    "Both of performances of the original model and Foundation-Sec-8B have improved, and finetuned Foundation-Sec-8B still outperforms the finetuned llama."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
