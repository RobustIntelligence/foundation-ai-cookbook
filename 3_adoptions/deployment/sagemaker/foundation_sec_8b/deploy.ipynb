{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04715d1-8e33-4805-a5e1-87ed9efab3e8",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "Let's deploy Foundation AI models onto Amazon SageMaker AI. <br>\n",
    "You can use the model deployed by this notebook for inference.  Refer to [the inference notebook](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/deployment/sagemaker/foundation_sec_8b/inference.ipynb) for sample code.\n",
    "\n",
    "As a prerequisite, please launch JupyterLab on SageMaker in your AWS environment. For more details, visit: \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-jl.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b702d00-a569-4065-bfc2-c398937d23cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T03:58:05.203878Z",
     "iopub.status.busy": "2025-06-09T03:58:05.203266Z",
     "iopub.status.idle": "2025-06-09T03:58:07.617368Z",
     "shell.execute_reply": "2025-06-09T03:58:07.616690Z",
     "shell.execute_reply.started": "2025-06-09T03:58:05.203847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ea6e45-8c7d-49ac-bc1a-3381ac21f19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T03:58:07.619075Z",
     "iopub.status.busy": "2025-06-09T03:58:07.618675Z",
     "iopub.status.idle": "2025-06-09T03:58:07.622784Z",
     "shell.execute_reply": "2025-06-09T03:58:07.622009Z",
     "shell.execute_reply.started": "2025-06-09T03:58:07.619045Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'fdtn-ai/Foundation-Sec-8B'\n",
    "HUGGING_FACE_HUB_TOKEN = '' # Your Hugging Face Token\n",
    "INSTANCE_TYPE = 'ml.g5.2xlarge'\n",
    "TIMEOUT = 900\n",
    "\n",
    "# You can also change other variables\n",
    "hub = {\n",
    "    'HF_MODEL_ID': MODEL_NAME,\n",
    "    'HF_TASK': 'text-generation',\n",
    "    'SM_NUM_GPUS': '1',\n",
    "    'MAX_INPUT_LENGTH': '2048',\n",
    "    'MAX_TOTAL_TOKENS': '4096',\n",
    "    'HUGGING_FACE_HUB_TOKEN': HUGGING_FACE_HUB_TOKEN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4aaf44-1ea5-43de-ba24-d309ad165370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T03:58:07.624122Z",
     "iopub.status.busy": "2025-06-09T03:58:07.623823Z",
     "iopub.status.idle": "2025-06-09T04:05:10.859557Z",
     "shell.execute_reply": "2025-06-09T04:05:10.858948Z",
     "shell.execute_reply.started": "2025-06-09T03:58:07.624095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\", version=\"3.2.0\"),\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    container_startup_health_check_timeout=TIMEOUT,\n",
    "  )\n",
    "\n",
    "# get the endpint to be used for inference (this can also be found on AWS console)\n",
    "# print(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bc4d6-2c14-4917-a017-db9622b8b675",
   "metadata": {},
   "source": [
    "The predictor's endpoint will be used for [inference](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/3_adoptions/deployment/sagemaker/foundation_sec_8b/inference.ipynb). You can get the endpoint from SageMaker Studio's console."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
